#!/usr/bin/env python3
"""
ç‹¬ç«‹çš„æ¨¡å‹è®­ç»ƒç»“æœå¯è§†åŒ–å·¥å…·
åŠŸèƒ½ï¼š
1. ç»˜åˆ¶å®Œæ•´çš„è®­ç»ƒæ›²çº¿ï¼ˆæ‰€æœ‰epochsï¼‰
2. æ£€æµ‹å¹¶æ ‡è®°resumeç‚¹ï¼ˆè®­ç»ƒä¸­æ–­æ¢å¤ï¼‰
3. æ˜¾ç¤ºé…ç½®ä¿¡æ¯å’Œæœ€ä½³æ¨¡å‹æ€§èƒ½
4. ä¿å­˜æ‰€æœ‰å¯è§†åŒ–ç»“æœåˆ°æŒ‡å®šç›®å½•

ä½¿ç”¨æ–¹æ³•:
    # è‡ªåŠ¨æ£€æµ‹resumeç‚¹
    python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321
    
    # æ‰‹åŠ¨æŒ‡å®šresumeç‚¹ï¼ˆæ¨èï¼‰
    python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321 --resume_epochs 4,11
    
    # å¯¹äºä½ çš„å…·ä½“ä¾‹å­ï¼š3æ¬¡epochæ—¶ä¸­æ–­ï¼Œ10epochæ—¶ä¸­æ–­ï¼Œæœ€ç»ˆåˆ°20epoch
    python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321 --resume_epochs 4,11
"""

import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
import argparse
from datetime import datetime
from pathlib import Path
import shutil

# è®¾ç½®ä¸­æ–‡å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial']
plt.rcParams['axes.unicode_minus'] = False
plt.style.use('default')
plt.rcParams['figure.facecolor'] = 'white'
plt.rcParams['axes.facecolor'] = 'white'
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3

class MetricsVisualizer:
    """è®­ç»ƒç»“æœå¯è§†åŒ–å™¨"""
    
    def __init__(self, output_dir, resume_epochs=None):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            output_dir: æ¨¡å‹è¾“å‡ºç›®å½•è·¯å¾„
            resume_epochs: æ‰‹åŠ¨æŒ‡å®šçš„resume epochsåˆ—è¡¨ï¼Œä¾‹å¦‚ [3, 7, 12]
        """
        self.output_dir = Path(output_dir)
        self.resume_epochs = resume_epochs or []
        
        # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
        if not self.output_dir.exists():
            raise FileNotFoundError(f"Output directory not found: {output_dir}")
        
        # åˆ›å»ºæ–°çš„å¯è§†åŒ–ç›®å½•
        date_str = datetime.now().strftime("%Y%m%d")
        self.vis_dir = self.output_dir / f"new_vis_date{date_str}"
        self.vis_dir.mkdir(exist_ok=True)
        
        print(f"âœ… å¯è§†åŒ–ç»“æœå°†ä¿å­˜åˆ°: {self.vis_dir}")
        
        # åŠ è½½æ•°æ®
        self.load_data()
    
    def load_data(self):
        """åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®æ–‡ä»¶"""
        print("ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®...")
        
        # åŠ è½½metricsæ•°æ®
        metrics_file = self.output_dir / "metrics.csv"
        if not metrics_file.exists():
            raise FileNotFoundError(f"Metrics file not found: {metrics_file}")
        
        self.metrics_df = pd.read_csv(metrics_file)
        self.metrics_df['timestamp'] = pd.to_datetime(self.metrics_df['timestamp'])
        
        print(f"   - åŠ è½½ {len(self.metrics_df)} ä¸ªepochçš„è®­ç»ƒæ•°æ®")
        
        # åŠ è½½é…ç½®ä¿¡æ¯
        config_file = self.output_dir / "config.json"
        if config_file.exists():
            with open(config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            print("   - åŠ è½½é…ç½®ä¿¡æ¯")
        else:
            self.config = {}
            print("   - âš ï¸ é…ç½®æ–‡ä»¶æœªæ‰¾åˆ°")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹ä¿¡æ¯
        best_model_file = self.output_dir / "best_model_info.json"
        if best_model_file.exists():
            with open(best_model_file, 'r', encoding='utf-8') as f:
                self.best_model_info = json.load(f)
            print("   - åŠ è½½æœ€ä½³æ¨¡å‹ä¿¡æ¯")
        else:
            self.best_model_info = {}
            print("   - âš ï¸ æœ€ä½³æ¨¡å‹ä¿¡æ¯æœªæ‰¾åˆ°")
    
    def detect_resume_points(self):
        """
        è‡ªåŠ¨æ£€æµ‹è®­ç»ƒä¸­æ–­æ¢å¤ç‚¹
        é€šè¿‡åˆ†ææ—¶é—´æˆ³é—´éš”æ¥è¯†åˆ«å¯èƒ½çš„resumeç‚¹
        """
        if len(self.resume_epochs) > 0:
            print(f"ğŸ“ ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„resumeç‚¹: {self.resume_epochs}")
            # éªŒè¯æ‰‹åŠ¨æŒ‡å®šçš„resumeç‚¹æ˜¯å¦æœ‰æ•ˆ
            valid_resume_points = []
            for resume_epoch in self.resume_epochs:
                if resume_epoch in self.metrics_df['epoch'].values:
                    valid_resume_points.append(resume_epoch)
                    print(f"   âœ… Resumeç‚¹ Epoch {resume_epoch} æœ‰æ•ˆ")
                else:
                    print(f"   âŒ Resumeç‚¹ Epoch {resume_epoch} æ— æ•ˆï¼ˆä¸å­˜åœ¨äºæ•°æ®ä¸­ï¼‰")
            return valid_resume_points
        
        print("ğŸ” è‡ªåŠ¨æ£€æµ‹è®­ç»ƒä¸­æ–­æ¢å¤ç‚¹...")
        
        # è®¡ç®—ç›¸é‚»epochä¹‹é—´çš„æ—¶é—´é—´éš”
        time_diffs = self.metrics_df['timestamp'].diff()
        
        # è®¡ç®—æ­£å¸¸è®­ç»ƒæ—¶é—´çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ’é™¤ç¬¬ä¸€ä¸ªNaNå€¼å’Œå¼‚å¸¸å€¼ï¼‰
        normal_diffs = time_diffs[1:].copy()
        
        # ä½¿ç”¨IQRæ–¹æ³•è¯†åˆ«å¼‚å¸¸æ—¶é—´é—´éš”
        q1 = normal_diffs.quantile(0.25)
        q3 = normal_diffs.quantile(0.75)
        iqr = q3 - q1
        median_time = normal_diffs.median()
        
        # è®¾ç½®é˜ˆå€¼ï¼šè¶…è¿‡ä¸­ä½æ•°çš„5å€æˆ–è€…Q3 + 3*IQRçš„è¾ƒå°å€¼
        threshold = min(median_time * 5, q3 + 3 * iqr)
        
        print(f"   - æ­£å¸¸è®­ç»ƒæ—¶é—´ä¸­ä½æ•°: {median_time.total_seconds()/3600:.2f} å°æ—¶")
        print(f"   - å¼‚å¸¸æ—¶é—´é—´éš”é˜ˆå€¼: {threshold.total_seconds()/3600:.2f} å°æ—¶")
        
        resume_points = []
        
        for i, diff in enumerate(time_diffs):
            if pd.notna(diff) and diff > threshold:
                resume_epoch = self.metrics_df.iloc[i]['epoch']
                resume_points.append(resume_epoch)
                time_gap = diff.total_seconds() / 3600  # è½¬æ¢ä¸ºå°æ—¶
                prev_epoch = self.metrics_df.iloc[i-1]['epoch'] if i > 0 else 0
                print(f"   - æ£€æµ‹åˆ°resumeç‚¹: Epoch {prev_epoch} â†’ {resume_epoch} (é—´éš” {time_gap:.1f} å°æ—¶)")
        
        if not resume_points:
            print("   - æœªæ£€æµ‹åˆ°è®­ç»ƒä¸­æ–­")
        
        return resume_points
    
    def parse_array_column(self, series):
        """è§£æå­—ç¬¦ä¸²å½¢å¼çš„æ•°ç»„åˆ—"""
        def parse_array(s):
            if isinstance(s, str):
                # ç§»é™¤æ–¹æ‹¬å·å¹¶åˆ†å‰²
                s = s.strip('[]')
                return [float(x.strip()) for x in s.split(',')]
            return s
        
        return series.apply(parse_array)
    
    def plot_training_curves(self):
        """ç»˜åˆ¶å®Œæ•´çš„è®­ç»ƒæ›²çº¿"""
        print("ğŸ“ˆ ç»˜åˆ¶è®­ç»ƒæ›²çº¿...")
        
        resume_points = self.detect_resume_points()
        
        # è§£ææ•°ç»„ç±»å‹çš„åˆ—
        iou_per_class = self.parse_array_column(self.metrics_df['iou_per_class'])
        dice_per_class = self.parse_array_column(self.metrics_df['dice_per_class'])
        acc_per_class = self.parse_array_column(self.metrics_df['acc_per_class'])
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(3, 2, figsize=(20, 15))
        fig.suptitle(f'Training Metrics - {self.output_dir.name}', fontsize=16, fontweight='bold')
        
        # 1. Lossæ›²çº¿
        ax = axes[0, 0]
        ax.plot(self.metrics_df['epoch'], self.metrics_df['train_loss'], 
               'b-', marker='o', linewidth=2, markersize=4, label='Train Loss')
        ax.plot(self.metrics_df['epoch'], self.metrics_df['val_loss'], 
               'r-', marker='s', linewidth=2, markersize=4, label='Val Loss')
        
        # æ ‡è®°resumeç‚¹
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
            ax.text(resume_epoch, ax.get_ylim()[1]*0.9, f'Resume\nEpoch {resume_epoch}', 
                   ha='center', va='top', bbox=dict(boxstyle="round,pad=0.3", facecolor='orange', alpha=0.7))
        
        ax.set_title('Training & Validation Loss', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 2. IoUæ›²çº¿
        ax = axes[0, 1]
        ax.plot(self.metrics_df['epoch'], self.metrics_df['miou'], 
               'g-', marker='d', linewidth=2, markersize=4, label='Mean IoU')
        
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        
        ax.set_title('Mean Intersection over Union (mIoU)', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('mIoU')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 3. Diceç³»æ•°æ›²çº¿
        ax = axes[1, 0]
        ax.plot(self.metrics_df['epoch'], self.metrics_df['mdice'], 
               'purple', marker='^', linewidth=2, markersize=4, label='Mean Dice')
        
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        
        ax.set_title('Mean Dice Coefficient', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Dice')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. Accuracyæ›²çº¿
        ax = axes[1, 1]
        ax.plot(self.metrics_df['epoch'], self.metrics_df['macc'], 
               'brown', marker='v', linewidth=2, markersize=4, label='Mean Accuracy')
        
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        
        ax.set_title('Mean Accuracy', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Accuracy')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 5. æ¯ç±»IoUæ›²çº¿
        ax = axes[2, 0]
        class_names = ['Class 0', 'Class 1', 'Class 2']
        colors = ['red', 'green', 'blue']
        
        for i in range(3):
            class_ious = [iou_list[i] for iou_list in iou_per_class]
            ax.plot(self.metrics_df['epoch'], class_ious, 
                   color=colors[i], marker='o', linewidth=2, markersize=3, 
                   label=f'{class_names[i]} IoU')
        
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        
        ax.set_title('Per-Class IoU', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('IoU')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 6. æ¯ç±»Diceæ›²çº¿
        ax = axes[2, 1]
        for i in range(3):
            class_dices = [dice_list[i] for dice_list in dice_per_class]
            ax.plot(self.metrics_df['epoch'], class_dices, 
                   color=colors[i], marker='s', linewidth=2, markersize=3, 
                   label=f'{class_names[i]} Dice')
        
        for resume_epoch in resume_points:
            ax.axvline(x=resume_epoch, color='orange', linestyle='--', alpha=0.7, linewidth=2)
        
        ax.set_title('Per-Class Dice Coefficient', fontweight='bold')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Dice')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        curve_file = self.vis_dir / "training_curves_complete.png"
        plt.savefig(curve_file, dpi=300, bbox_inches='tight')
        print(f"   - è®­ç»ƒæ›²çº¿ä¿å­˜åˆ°: {curve_file}")
        
        plt.show()
        
        return resume_points
    
    def plot_resume_analysis(self, resume_points):
        """ç»˜åˆ¶resumeç‚¹åˆ†æå›¾"""
        if not resume_points:
            print("ğŸ“Š æ— resumeç‚¹ï¼Œè·³è¿‡resumeåˆ†æ")
            return
        
        print("ğŸ“Š ç»˜åˆ¶resumeç‚¹åˆ†æ...")
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'Resume Points Analysis - {len(resume_points)} Resumes Detected', 
                    fontsize=14, fontweight='bold')
        
        # 1. æ—¶é—´è½´åˆ†æ
        ax = axes[0, 0]
        timestamps = self.metrics_df['timestamp']
        epochs = self.metrics_df['epoch']
        
        ax.plot(timestamps, epochs, 'b-', marker='o', markersize=4, alpha=0.7)
        
        for resume_epoch in resume_points:
            resume_time = self.metrics_df[self.metrics_df['epoch'] == resume_epoch]['timestamp'].iloc[0]
            ax.axvline(x=resume_time, color='red', linestyle='--', alpha=0.8, linewidth=2)
            ax.plot(resume_time, resume_epoch, 'ro', markersize=8)
        
        ax.set_title('Training Timeline with Resume Points')
        ax.set_xlabel('Timestamp')
        ax.set_ylabel('Epoch')
        ax.grid(True, alpha=0.3)
        
        # æ ¼å¼åŒ–xè½´æ—¶é—´æ˜¾ç¤º
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))
        ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)
        
        # 2. è®­ç»ƒé—´éš”åˆ†æ
        ax = axes[0, 1]
        time_diffs = self.metrics_df['timestamp'].diff()
        time_diffs_hours = time_diffs.dt.total_seconds() / 3600
        
        ax.bar(self.metrics_df['epoch'][1:], time_diffs_hours[1:], 
               color='lightblue', alpha=0.7, edgecolor='navy')
        
        for resume_epoch in resume_points:
            if resume_epoch > 1:
                idx = self.metrics_df[self.metrics_df['epoch'] == resume_epoch].index[0]
                if idx > 0:
                    ax.bar(resume_epoch, time_diffs_hours.iloc[idx], 
                          color='red', alpha=0.8, edgecolor='darkred')
        
        ax.set_title('Time Intervals Between Epochs')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Hours')
        ax.grid(True, alpha=0.3)
        
        # 3. Resumeå‰åæ€§èƒ½å¯¹æ¯”
        ax = axes[1, 0]
        metrics_to_compare = ['val_loss', 'miou', 'mdice']
        x_pos = np.arange(len(metrics_to_compare))
        
        before_resume_avg = []
        after_resume_avg = []
        
        for metric in metrics_to_compare:
            before_vals = []
            after_vals = []
            
            for resume_epoch in resume_points:
                # Resumeå‰çš„å€¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                before_idx = self.metrics_df[self.metrics_df['epoch'] == resume_epoch - 1].index
                if len(before_idx) > 0:
                    before_vals.append(self.metrics_df.loc[before_idx[0], metric])
                
                # Resumeåçš„å€¼
                after_idx = self.metrics_df[self.metrics_df['epoch'] == resume_epoch].index
                if len(after_idx) > 0:
                    after_vals.append(self.metrics_df.loc[after_idx[0], metric])
            
            before_resume_avg.append(np.mean(before_vals) if before_vals else 0)
            after_resume_avg.append(np.mean(after_vals) if after_vals else 0)
        
        width = 0.35
        ax.bar(x_pos - width/2, before_resume_avg, width, label='Before Resume', 
               color='lightcoral', alpha=0.8)
        ax.bar(x_pos + width/2, after_resume_avg, width, label='After Resume', 
               color='lightgreen', alpha=0.8)
        
        ax.set_title('Performance Before vs After Resume')
        ax.set_xlabel('Metrics')
        ax.set_ylabel('Value')
        ax.set_xticks(x_pos)
        ax.set_xticklabels(metrics_to_compare)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 4. Resumeç»Ÿè®¡ä¿¡æ¯
        ax = axes[1, 1]
        ax.axis('off')
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        total_training_time = (timestamps.iloc[-1] - timestamps.iloc[0]).total_seconds() / 3600
        
        # è®¡ç®—çº¯è®­ç»ƒæ—¶é—´ï¼ˆæ’é™¤ä¸­æ–­æ—¶é—´ï¼‰
        pure_training_time = 0
        for i in range(1, len(time_diffs_hours)):
            if not pd.isna(time_diffs_hours.iloc[i]):
                # å¦‚æœè¿™ä¸ªé—´éš”ä¸æ˜¯resumeé—´éš”ï¼ˆå³æ­£å¸¸è®­ç»ƒæ—¶é—´ï¼‰
                epoch = self.metrics_df.iloc[i]['epoch']
                if epoch not in resume_points:
                    pure_training_time += time_diffs_hours.iloc[i]
        
        avg_epoch_time = pure_training_time / (len(epochs) - len(resume_points)) if len(epochs) > len(resume_points) else 0
        
        # è®¡ç®—è®­ç»ƒæ®µè½
        training_segments = []
        if resume_points:
            # æ·»åŠ ç¬¬ä¸€æ®µ
            start_epoch = 1
            for resume_epoch in resume_points:
                end_epoch = resume_epoch - 1
                if end_epoch >= start_epoch:
                    training_segments.append((start_epoch, end_epoch))
                start_epoch = resume_epoch
            
            # æ·»åŠ æœ€åä¸€æ®µ
            if start_epoch <= epochs.iloc[-1]:
                training_segments.append((start_epoch, epochs.iloc[-1]))
        else:
            training_segments = [(1, epochs.iloc[-1])]
        
        resume_info = [
            f"Total Resumes: {len(resume_points)}",
            f"Resume Epochs: {', '.join(map(str, resume_points))}",
            f"Total Wall Time: {total_training_time:.1f} hours",
            f"Pure Training Time: {pure_training_time:.1f} hours",
            f"Average Epoch Time: {avg_epoch_time:.2f} hours",
            f"Training Segments: {len(training_segments)}",
        ]
        
        # æ·»åŠ è®­ç»ƒæ®µè½ä¿¡æ¯
        for i, (start, end) in enumerate(training_segments[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ªæ®µè½
            resume_info.append(f"  Segment {i+1}: Epoch {start}-{end}")
        
        if len(training_segments) > 3:
            resume_info.append(f"  ... and {len(training_segments)-3} more")
        
        if len(time_diffs_hours) > 1:
            longest_break = time_diffs_hours.max()
            resume_info.append(f"Longest Break: {longest_break:.1f} hours")
        
        y_pos = 0.95
        for info in resume_info:
            fontsize = 10 if info.startswith('  ') else 12
            weight = 'normal' if info.startswith('  ') else 'bold'
            ax.text(0.05, y_pos, info, fontsize=fontsize, fontweight=weight, 
                   transform=ax.transAxes)
            y_pos -= 0.08
        
        ax.set_title('Resume Statistics', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        resume_file = self.vis_dir / "resume_analysis.png"
        plt.savefig(resume_file, dpi=300, bbox_inches='tight')
        print(f"   - Resumeåˆ†æä¿å­˜åˆ°: {resume_file}")
        
        plt.show()
    
    def create_config_summary(self):
        """åˆ›å»ºé…ç½®ä¿¡æ¯æ‘˜è¦"""
        print("âš™ï¸ ç”Ÿæˆé…ç½®ä¿¡æ¯æ‘˜è¦...")
        
        fig, axes = plt.subplots(1, 2, figsize=(16, 10))
        fig.suptitle(f'Model Configuration Summary - {self.output_dir.name}', 
                    fontsize=14, fontweight='bold')
        
        # 1. ä¸»è¦é…ç½®ä¿¡æ¯
        ax = axes[0]
        ax.axis('off')
        
        if 'config' in self.config:
            config_data = self.config['config']
            
            main_config = [
                f"Model: {config_data.get('model', 'N/A')}",
                f"Image Size: {config_data.get('img_size', 'N/A')}",
                f"Batch Size: {config_data.get('batch_size', 'N/A')}",
                f"Epochs: {config_data.get('epochs', 'N/A')}",
                f"Learning Rate: {config_data.get('lr', 'N/A')}",
                f"Optimizer: {config_data.get('optimizer', 'N/A')}",
                f"Scheduler: {config_data.get('scheduler', 'N/A')}",
                f"Weight Decay: {config_data.get('weight_decay', 'N/A')}",
                f"Val Ratio: {config_data.get('val_ratio', 'N/A')}",
                f"Num Classes: {config_data.get('num_classes', 'N/A')}",
                f"Classification: {config_data.get('classification_scheme', 'N/A')}",
                f"Augmentation: {config_data.get('augment', 'N/A')}",
                f"Flip Prob: {config_data.get('flip_prob', 'N/A')}",
                f"Rotation: {config_data.get('rotation_degree', 'N/A')}Â°",
                f"FOV Mask: {config_data.get('apply_fov_mask', 'N/A')}",
                f"Early Stopping: {config_data.get('early_stopping', 'N/A')}",
                f"Patience: {config_data.get('patience', 'N/A')}"
            ]
            
            y_pos = 0.95
            for config_item in main_config:
                ax.text(0.05, y_pos, config_item, fontsize=11, 
                       transform=ax.transAxes, fontweight='bold')
                y_pos -= 0.05
        
        ax.set_title('Training Configuration', fontweight='bold', pad=20)
        
        # 2. æœ€ä½³æ¨¡å‹æ€§èƒ½
        ax = axes[1]
        ax.axis('off')
        
        if self.best_model_info:
            best_metrics = self.best_model_info.get('best_metrics', {})
            
            performance_info = [
                f"Best Epoch: {self.best_model_info.get('best_epoch', 'N/A')}",
                f"Best Val Loss: {best_metrics.get('val_loss', 'N/A'):.6f}",
                f"Best mIoU: {best_metrics.get('miou', 'N/A'):.4f}",
                f"Best mDice: {best_metrics.get('mdice', 'N/A'):.4f}",
                f"Best mAcc: {best_metrics.get('macc', 'N/A'):.4f}",
                "",
                "Per-Class IoU:",
                f"  Class 0: {best_metrics.get('iou_per_class', [0,0,0])[0]:.4f}",
                f"  Class 1: {best_metrics.get('iou_per_class', [0,0,0])[1]:.4f}",
                f"  Class 2: {best_metrics.get('iou_per_class', [0,0,0])[2]:.4f}",
                "",
                "Per-Class Dice:",
                f"  Class 0: {best_metrics.get('dice_per_class', [0,0,0])[0]:.4f}",
                f"  Class 1: {best_metrics.get('dice_per_class', [0,0,0])[1]:.4f}",
                f"  Class 2: {best_metrics.get('dice_per_class', [0,0,0])[2]:.4f}",
                "",
                f"Updated: {self.best_model_info.get('updated_at', 'N/A')}"
            ]
            
            y_pos = 0.95
            for perf_item in performance_info:
                color = 'red' if 'Best' in perf_item and perf_item != "" else 'black'
                weight = 'bold' if 'Best' in perf_item or 'Class' in perf_item else 'normal'
                ax.text(0.05, y_pos, perf_item, fontsize=11, color=color,
                       transform=ax.transAxes, fontweight=weight)
                y_pos -= 0.05
        
        ax.set_title('Best Model Performance', fontweight='bold', pad=20)
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        config_file = self.vis_dir / "config_summary.png"
        plt.savefig(config_file, dpi=300, bbox_inches='tight')
        print(f"   - é…ç½®æ‘˜è¦ä¿å­˜åˆ°: {config_file}")
        
        plt.show()
    
    def copy_existing_visualizations(self):
        """å¤åˆ¶ç°æœ‰çš„å¯è§†åŒ–æ–‡ä»¶"""
        print("ğŸ“‹ å¤åˆ¶ç°æœ‰å¯è§†åŒ–æ–‡ä»¶...")
        
        vis_source = self.output_dir / "visualizations"
        if vis_source.exists():
            # å¤åˆ¶æ•´ä¸ªvisualizationsç›®å½•
            vis_dest = self.vis_dir / "original_visualizations"
            if vis_dest.exists():
                shutil.rmtree(vis_dest)
            shutil.copytree(vis_source, vis_dest)
            print(f"   - åŸå§‹å¯è§†åŒ–æ–‡ä»¶å¤åˆ¶åˆ°: {vis_dest}")
        else:
            print("   - âš ï¸ æœªæ‰¾åˆ°åŸå§‹å¯è§†åŒ–æ–‡ä»¶")
    
    def generate_summary_report(self, resume_points):
        """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦æŠ¥å‘Š"""
        print("ğŸ“ ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š...")
        
        report_file = self.vis_dir / "training_summary_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"è®­ç»ƒç»“æœæ‘˜è¦æŠ¥å‘Š - {self.output_dir.name}\n")
            f.write("=" * 80 + "\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # åŸºæœ¬ä¿¡æ¯
            f.write("ã€åŸºæœ¬ä¿¡æ¯ã€‘\n")
            f.write(f"æ¨¡å‹è¾“å‡ºç›®å½•: {self.output_dir}\n")
            f.write(f"æ€»è®­ç»ƒè½®æ•°: {len(self.metrics_df)} epochs\n")
            f.write(f"è®­ç»ƒæ—¶é—´è·¨åº¦: {self.metrics_df['timestamp'].iloc[0]} -> {self.metrics_df['timestamp'].iloc[-1]}\n")
            
            # Resumeä¿¡æ¯
            f.write(f"\nã€Resumeä¿¡æ¯ã€‘\n")
            if resume_points:
                f.write(f"æ£€æµ‹åˆ° {len(resume_points)} æ¬¡è®­ç»ƒä¸­æ–­æ¢å¤\n")
                f.write(f"Resume epochs: {', '.join(map(str, resume_points))}\n")
                
                # è®¡ç®—æ¯æ®µè®­ç»ƒæ—¶é—´
                segments = []
                start_epoch = 1
                for resume_epoch in resume_points + [len(self.metrics_df) + 1]:
                    end_epoch = resume_epoch - 1
                    segments.append((start_epoch, end_epoch))
                    start_epoch = resume_epoch
                
                f.write("è®­ç»ƒæ®µè½:\n")
                for i, (start, end) in enumerate(segments[:-1]):
                    f.write(f"  æ®µè½ {i+1}: Epoch {start}-{end}\n")
            else:
                f.write("æ— è®­ç»ƒä¸­æ–­ï¼Œè¿ç»­è®­ç»ƒå®Œæˆ\n")
            
            # æœ€ä½³æ€§èƒ½
            f.write(f"\nã€æœ€ä½³æ€§èƒ½ã€‘\n")
            if self.best_model_info:
                best_metrics = self.best_model_info['best_metrics']
                f.write(f"æœ€ä½³epoch: {self.best_model_info['best_epoch']}\n")
                f.write(f"æœ€ä½³éªŒè¯æŸå¤±: {best_metrics['val_loss']:.6f}\n")
                f.write(f"æœ€ä½³mIoU: {best_metrics['miou']:.4f}\n")
                f.write(f"æœ€ä½³mDice: {best_metrics['mdice']:.4f}\n")
                f.write(f"æœ€ä½³mAcc: {best_metrics['macc']:.4f}\n")
            
            # æœ€ç»ˆæ€§èƒ½
            f.write(f"\nã€æœ€ç»ˆæ€§èƒ½ã€‘\n")
            final_metrics = self.metrics_df.iloc[-1]
            f.write(f"æœ€ç»ˆepoch: {final_metrics['epoch']}\n")
            f.write(f"æœ€ç»ˆè®­ç»ƒæŸå¤±: {final_metrics['train_loss']:.6f}\n")
            f.write(f"æœ€ç»ˆéªŒè¯æŸå¤±: {final_metrics['val_loss']:.6f}\n")
            f.write(f"æœ€ç»ˆmIoU: {final_metrics['miou']:.4f}\n")
            f.write(f"æœ€ç»ˆmDice: {final_metrics['mdice']:.4f}\n")
            f.write(f"æœ€ç»ˆmAcc: {final_metrics['macc']:.4f}\n")
            
            # é…ç½®ä¿¡æ¯
            if 'config' in self.config:
                config_data = self.config['config']
                f.write(f"\nã€è®­ç»ƒé…ç½®ã€‘\n")
                key_configs = ['model', 'img_size', 'batch_size', 'epochs', 'lr', 
                              'optimizer', 'scheduler', 'weight_decay', 'val_ratio', 
                              'num_classes', 'classification_scheme']
                for key in key_configs:
                    if key in config_data:
                        f.write(f"{key}: {config_data[key]}\n")
            
            f.write("\n" + "=" * 80 + "\n")
        
        print(f"   - æ‘˜è¦æŠ¥å‘Šä¿å­˜åˆ°: {report_file}")
    
    def run_complete_visualization(self):
        """è¿è¡Œå®Œæ•´çš„å¯è§†åŒ–æµç¨‹"""
        print(f"\nğŸ¨ å¼€å§‹å®Œæ•´å¯è§†åŒ–æµç¨‹...")
        print(f"ç›®æ ‡ç›®å½•: {self.output_dir}")
        print(f"ä¿å­˜ç›®å½•: {self.vis_dir}")
        print("-" * 60)
        
        # 1. ç»˜åˆ¶è®­ç»ƒæ›²çº¿å¹¶æ£€æµ‹resumeç‚¹
        resume_points = self.plot_training_curves()
        
        # 2. ç»˜åˆ¶resumeåˆ†æ
        self.plot_resume_analysis(resume_points)
        
        # 3. åˆ›å»ºé…ç½®æ‘˜è¦
        self.create_config_summary()
        
        # 4. å¤åˆ¶ç°æœ‰å¯è§†åŒ–æ–‡ä»¶
        self.copy_existing_visualizations()
        
        # 5. ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
        self.generate_summary_report(resume_points)
        
        print("-" * 60)
        print(f"âœ… å¯è§†åŒ–å®Œæˆï¼æ‰€æœ‰æ–‡ä»¶ä¿å­˜åœ¨: {self.vis_dir}")
        print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        for file_path in self.vis_dir.rglob("*"):
            if file_path.is_file():
                print(f"   - {file_path.relative_to(self.vis_dir)}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å¯è§†åŒ–è®­ç»ƒç»“æœ - ç‹¬ç«‹çš„metricsåˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # è‡ªåŠ¨æ£€æµ‹resumeç‚¹
  python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321
  
  # æ‰‹åŠ¨æŒ‡å®šresumeç‚¹ï¼ˆæ¨èï¼Œæ›´å‡†ç¡®ï¼‰
  python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321 --resume_epochs 4,11
  
  # å¯¹äºè®­ç»ƒåœ¨epoch 3å’Œ10ä¸­æ–­çš„æƒ…å†µï¼Œresumeç‚¹åº”è¯¥æ˜¯4å’Œ11
  python scripts/visualize_metrics.py --output_dir outputs/unet_plus_plus_20250911_230321 --resume_epochs 4,11

æ³¨æ„ï¼š
  - resume_epochs æŒ‡çš„æ˜¯æ¢å¤è®­ç»ƒåçš„ç¬¬ä¸€ä¸ªepoch
  - å¦‚æœåœ¨epoch 3ä¸­æ–­ï¼Œé‚£ä¹ˆresumeç‚¹æ˜¯epoch 4
  - æ”¯æŒå¤šä¸ªresumeç‚¹ï¼Œç”¨é€—å·åˆ†éš”
        """)
    
    parser.add_argument('--output_dir', type=str, required=True,
                       help='æ¨¡å‹è¾“å‡ºç›®å½•è·¯å¾„ï¼Œä¾‹å¦‚: outputs/unet_plus_plus_20250911_230321')
    parser.add_argument('--resume_epochs', type=str, default=None,
                       help='æ‰‹åŠ¨æŒ‡å®šresume epochsï¼Œç”¨é€—å·åˆ†éš”ã€‚æ³¨æ„ï¼šè¿™æ˜¯æ¢å¤åçš„epochï¼Œä¸æ˜¯ä¸­æ–­çš„epochã€‚ä¾‹å¦‚: 4,11')
    
    args = parser.parse_args()
    
    # è§£æresume epochs
    resume_epochs = None
    if args.resume_epochs:
        try:
            resume_epochs = [int(x.strip()) for x in args.resume_epochs.split(',')]
            resume_epochs = sorted(list(set(resume_epochs)))  # å»é‡å¹¶æ’åº
            print(f"ğŸ¯ å°†ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šçš„resumeç‚¹: {resume_epochs}")
        except ValueError:
            print("âŒ resume_epochsæ ¼å¼é”™è¯¯ï¼Œåº”è¯¥æ˜¯ç”¨é€—å·åˆ†éš”çš„æ•°å­—ï¼Œä¾‹å¦‚: 4,11")
            print("ğŸ’¡ æç¤ºï¼šresume_epochsæ˜¯æ¢å¤è®­ç»ƒåçš„ç¬¬ä¸€ä¸ªepochï¼Œä¸æ˜¯ä¸­æ–­çš„epoch")
            return
    
    try:
        # åˆ›å»ºå¯è§†åŒ–å™¨å¹¶è¿è¡Œ
        visualizer = MetricsVisualizer(args.output_dir, resume_epochs)
        visualizer.run_complete_visualization()
        
        print("\nğŸ‰ å¯è§†åŒ–å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
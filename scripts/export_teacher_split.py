# scripts/export_teacher_split.py
"""
å¯¼å‡ºTeacherè®­ç»ƒæ—¶ä½¿ç”¨çš„è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†
ç”¨äºç¡®ä¿KDå®éªŒä½¿ç”¨ä¸Teacherå®Œå…¨ç›¸åŒçš„éªŒè¯é›†
"""
import os
import yaml
import torch
from src.dataio.datasets.seg_dataset_min import SegDatasetMin  # ä¿®æ­£ç±»å
from src.common.constants import compose_mapping

# Teacherè®­ç»ƒæ—¶çš„ç²¾ç¡®å‚æ•° - è¯·ç¡®ä¿ä¸Teacherè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
DATA_ROOT = "data/seg8k"
IMG_SIZE = 384
VAL_RATIO = 0.25
SEED = 42
APPLY_FOV = True
CLASSIFICATION_SCHEME = "3class_org"  # ä¸Teacheré…ç½®ä¸€è‡´

print("ğŸ” Extracting Teacher's original train/val split...")
print(f"Parameters: img_size={IMG_SIZE}, val_ratio={VAL_RATIO}, seed={SEED}")
print(f"FOV mask: {APPLY_FOV}, classification: {CLASSIFICATION_SCHEME}")

# === é‡è¦ï¼šä¸Teacherå®Œå…¨ä¸€è‡´çš„æ•°æ®é›†é…ç½® ===
class_id_map = compose_mapping(
    classification_scheme=CLASSIFICATION_SCHEME,
    custom_mapping=None,
    target_classes=None
)

dataset_config = {
    "class_id_map": class_id_map,
    "return_multiclass": True,  # å¤šåˆ†ç±»æ¨¡å¼
    "apply_fov_mask": APPLY_FOV
}

# æ„é€ ä¸Teacherç›¸åŒçš„æ•°æ®é›†
full_dataset = SegDatasetMin(
    DATA_ROOT, 
    dtype="train", 
    img_size=IMG_SIZE,
    **dataset_config
)

print(f"Dataset loaded: {len(full_dataset)} samples")

# ä½¿ç”¨Teacherçš„åŸå§‹random_splité€»è¾‘ï¼ˆå¸§çº§åˆ’åˆ†ï¼‰
N = len(full_dataset)
val_size = int(N * VAL_RATIO)
train_size = N - val_size
g = torch.Generator().manual_seed(SEED)
train_ds, val_ds = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=g)

# æå–è®­ç»ƒ/éªŒè¯çš„å›¾åƒè·¯å¾„
def get_image_path(idx):
    return full_dataset.pairs[idx][0]  # (img_path, mask_path)

train_paths = [get_image_path(i) for i in train_ds.indices]
val_paths = [get_image_path(i) for i in val_ds.indices]

# ä¿å­˜Teacherçš„åˆ†å‰²ä¿¡æ¯
os.makedirs("splits", exist_ok=True)
teacher_split = {
    "train": train_paths,
    "val": val_paths,
    "metadata": {
        "total_samples": N,
        "train_samples": len(train_paths),
        "val_samples": len(val_paths),
        "actual_val_ratio": len(val_paths) / N,
        "seed": SEED,
        "img_size": IMG_SIZE,
        "apply_fov_mask": APPLY_FOV,
        "classification_scheme": CLASSIFICATION_SCHEME,
        "split_method": "frame_random",
        "source": "teacher_training",
        "export_date": "2025-09-19"
    }
}

output_file = "splits/teacher_frame_split.yaml"
with open(output_file, "w") as f:
    yaml.safe_dump(teacher_split, f, sort_keys=False)

print(f"âœ… Teacher split exported:")
print(f"   Train: {len(train_paths)} samples")  
print(f"   Val: {len(val_paths)} samples")
print(f"   Ratio: {len(val_paths)/N:.3f}")
print(f"   Saved to: {output_file}")
print(f"\nğŸ“‹ To use this split in experiments, add to config:")
print(f"   split_strategy: from_file")
print(f"   split_file: {output_file}")
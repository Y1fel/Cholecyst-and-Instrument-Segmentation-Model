"""
é€šç”¨è®­ç»ƒæ¨¡æ¿ - é›†æˆç›‘æ§ã€å¯è§†åŒ–ã€è¯„ä¼°åŠŸèƒ½
åŸºäºtrain_offline_minæ”¹è¿›ï¼Œé€‚ç”¨äºå„ç§æ¨¡å‹çš„è®­ç»ƒ
"""
import os, argparse, yaml, torch
from torch import nn
from torch.utils.data import DataLoader

# å¯¼å…¥é€šç”¨æ¨¡å—
from src.metrics.evaluator import Evaluator
from src.viz.visualizer import Visualizer
from src.common.output_manager import OutputManager
from src.common.train_monitor import TrainMonitor

# ç¤ºä¾‹æ¨¡å‹å¯¼å…¥ - æ ¹æ®å®é™…æ¨¡å‹æ›¿æ¢
from src.dataio.datasets.seg_dataset_min import SegDatasetMin
from src.models.baseline.unet_min import UNetMin

def parse_args():
    """å‚æ•°é…ç½® - å¯æ ¹æ®ä¸åŒæ¨¡å‹éœ€æ±‚è°ƒæ•´"""
    p = argparse.ArgumentParser("Universal training template with monitoring.")
    
    # åŸºç¡€è®­ç»ƒå‚æ•°
    p.add_argument("--cfg", type=str, default=None, help="Optional YAML config")
    p.add_argument("--data_root", type=str, required=True, help="Dataset root path")
    p.add_argument("--model_type", type=str, default="universal", help="Model type identifier")
    
    # æ•°æ®å‚æ•°
    p.add_argument("--split", type=str, default="train")
    p.add_argument("--img_size", type=int, default=512)
    p.add_argument("--batch_size", type=int, default=6)
    p.add_argument("--val_ratio", type=float, default=0.2)
    p.add_argument("--num_workers", type=int, default=0)
    
    # è®­ç»ƒå‚æ•°
    p.add_argument("--epochs", type=int, default=5)
    p.add_argument("--lr", type=float, default=3e-4)
    p.add_argument("--num_classes", type=int, default=2)
    
    # ç›‘æ§å’Œè¾“å‡ºå‚æ•°
    p.add_argument("--monitor_interval", type=int, default=10, help="Progress update interval (batches)")
    p.add_argument("--enable_gpu_monitor", action='store_true', default=True, help="Enable GPU monitoring")
    p.add_argument("--save_viz", action='store_true', help="Save visualizations")
    p.add_argument("--viz_samples", type=int, default=50, help="Number of visualization samples")
    
    # è°ƒè¯•å’Œé«˜çº§é€‰é¡¹
    p.add_argument("--debug", action='store_true', help="Enable debug mode")
    p.add_argument("--save_best_only", action='store_true', default=True, help="Only save best checkpoints")
    
    return p.parse_args()

def setup_model_and_criterion(args, device):
    """
    æ¨¡å‹å’ŒæŸå¤±å‡½æ•°è®¾ç½® - æ ¹æ®ä¸åŒæ¨¡å‹ä¿®æ”¹æ­¤å‡½æ•°
    
    è¿”å›: model, criterion
    """
    # ç¤ºä¾‹ï¼šUNetæ¨¡å‹è®¾ç½®
    out_ch = 1 if args.num_classes == 2 else args.num_classes
    model = UNetMin(in_ch=3, num_classes=out_ch, base=32).to(device)
    
    # æŸå¤±å‡½æ•°é€‰æ‹©
    if args.num_classes == 2:
        criterion = nn.BCEWithLogitsLoss()
    else:
        criterion = nn.CrossEntropyLoss()
    
    return model, criterion

def setup_data_loaders(args):
    """
    æ•°æ®åŠ è½½å™¨è®¾ç½® - æ ¹æ®ä¸åŒæ•°æ®é›†ä¿®æ”¹æ­¤å‡½æ•°
    
    è¿”å›: train_loader, val_loader, dataset_info
    """
    # ç¤ºä¾‹ï¼šåˆ†å‰²æ•°æ®é›†è®¾ç½®
    full_dataset = SegDatasetMin(args.data_root, "", args.img_size)
    
    val_size = int(len(full_dataset) * args.val_ratio)
    train_size = len(full_dataset) - val_size
    train_dataset, val_dataset = torch.utils.data.random_split(
        full_dataset, [train_size, val_size]
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=args.num_workers,
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=args.num_workers,
        pin_memory=True
    )
    
    dataset_info = {
        'train_size': len(train_dataset),
        'val_size': len(val_dataset),
        'total_size': len(full_dataset)
    }
    
    return train_loader, val_loader, dataset_info

def train_one_epoch(model, train_loader, criterion, optimizer, device, monitor, epoch, args):
    """
    è®­ç»ƒä¸€ä¸ªepoch - é›†æˆç›‘æ§åŠŸèƒ½
    
    è¿”å›: å¹³å‡è®­ç»ƒæŸå¤±
    """
    model.train()
    running_loss = 0.0
    total_batches = len(train_loader)
    
    for batch_idx, (images, masks) in enumerate(train_loader):
        images = images.to(device, non_blocking=True)
        masks = masks.to(device, non_blocking=True)
        
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, masks)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad(set_to_none=True)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item() * images.size(0)
        
        # å®æ—¶ç›‘æ§æ˜¾ç¤º
        if batch_idx % args.monitor_interval == 0:
            current_avg_loss = running_loss / ((batch_idx + 1) * args.batch_size)
            monitor.print_progress(
                epoch + 1, args.epochs,
                batch_idx + 1, total_batches,
                {"loss": current_avg_loss},
                refresh=True
            )
    
    avg_train_loss = running_loss / len(train_loader.dataset)
    return avg_train_loss

def validate_model(model, val_loader, criterion, device):
    """
    æ¨¡å‹éªŒè¯ - ä½¿ç”¨é›†æˆçš„è¯„ä¼°å™¨
    
    è¿”å›: éªŒè¯æŒ‡æ ‡å­—å…¸
    """
    evaluator = Evaluator(device=device)
    val_metrics = evaluator.evaluate(model, val_loader, criterion)
    return val_metrics

def save_visualizations(model, val_loader, viz_dir, args, device):
    """
    ä¿å­˜å¯è§†åŒ–ç»“æœ - ä½¿ç”¨é›†æˆçš„å¯è§†åŒ–å™¨
    """
    visualizer = Visualizer()
    visualizer.save_basic_predictions(
        model,
        val_loader,
        viz_dir,
        max_samples=args.viz_samples,
        device=device
    )

def main():
    args = parse_args()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    
    print(f"Starting training with device: {device}")
    print(f"Model type: {args.model_type}")
    
    # åˆå§‹åŒ–ç›‘æ§å™¨
    monitor = TrainMonitor(enable_gpu_monitor=args.enable_gpu_monitor)
    monitor.start_timing()
    
    # åˆå§‹åŒ–è¾“å‡ºç®¡ç†å™¨
    output_mgr = OutputManager(model_type=args.model_type)
    output_mgr.save_config(vars(args))
    
    # è®¾ç½®æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, dataset_info = setup_data_loaders(args)
    print(f"ğŸ“ Dataset: Train={dataset_info['train_size']}, Val={dataset_info['val_size']}")
    
    # è®¾ç½®æ¨¡å‹å’ŒæŸå¤±å‡½æ•°
    model, criterion = setup_model_and_criterion(args, device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)
    
    # è®­ç»ƒçŠ¶æ€è·Ÿè¸ª
    best_val_loss = float("inf")
    
    print(f"ğŸ¯ Starting training for {args.epochs} epochs...")
    print("=" * 80)
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(args.epochs):
        # è®­ç»ƒé˜¶æ®µ
        avg_train_loss = train_one_epoch(
            model, train_loader, criterion, optimizer, device, monitor, epoch, args
        )
        
        # éªŒè¯é˜¶æ®µ
        print(f"\nğŸ” Validation for epoch {epoch + 1}...")
        val_metrics = validate_model(model, val_loader, criterion, device)
        
        # ç»„åˆæŒ‡æ ‡
        combined_metrics = {"train_loss": avg_train_loss}
        combined_metrics.update(val_metrics)
        
        # ä¿å­˜æŒ‡æ ‡åˆ°CSV
        output_mgr.save_metrics_csv(combined_metrics, epoch + 1)
        
        # æ˜¾ç¤ºepochæ€»ç»“
        train_metrics = {"loss": avg_train_loss}
        monitor.print_epoch_summary(epoch + 1, train_metrics, val_metrics)
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_metrics['val_loss'] < best_val_loss:
            best_val_loss = val_metrics['val_loss']
            output_mgr.save_model(model, epoch + 1, val_metrics)
            print(f"âœ… Saved best model at epoch {epoch + 1} with val_loss {val_metrics['val_loss']:.4f}")
        
        # ä¿å­˜å¯è§†åŒ–ç»“æœï¼ˆå¯é€‰ï¼‰
        if args.save_viz and (epoch + 1) % max(1, args.epochs // 3) == 0:
            print(f"ğŸ¨ Saving visualizations for epoch {epoch + 1}...")
            viz_dir = os.path.join(output_mgr.get_vis_dir(), f"epoch_{epoch + 1:03d}")
            save_visualizations(model, val_loader, viz_dir, args, device)
    
    # è®­ç»ƒå®Œæˆæ€»ç»“
    summary = output_mgr.get_run_summary()
    print("\n" + "=" * 80)
    print("ğŸ‰ Training Completed!")
    print(f"ğŸ“‚ Results saved to: {summary['run_dir']}")
    print(f"ğŸ“ˆ Best validation metrics:")
    print(f"   Loss: {best_val_loss:.4f}")
    print(f"â±ï¸  Total training time: {monitor.get_elapsed_time()}")
    
    # æœ€ç»ˆå¯è§†åŒ–ä¿å­˜
    if args.save_viz:
        print("ğŸ¨ Saving final visualizations...")
        final_viz_dir = output_mgr.get_vis_dir()
        save_visualizations(model, val_loader, final_viz_dir, args, device)

if __name__ == "__main__":
    main()

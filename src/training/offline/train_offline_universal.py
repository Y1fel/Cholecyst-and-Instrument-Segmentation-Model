# src/training/train_offline_universal.py
"""
é€šç”¨è®­ç»ƒæ¨¡æ¿ - é›†æˆç›‘æ§ã€å¯è§†åŒ–ã€è¯„ä¼°åŠŸèƒ½
åŸºäºtrain_offline_minæ”¹è¿›ï¼Œé€‚ç”¨äºå„ç§æ¨¡å‹çš„è®­ç»ƒ
"""

import os, argparse, yaml, torch
from torch import nn
from torch.utils.data import DataLoader

# å¯¼å…¥é€šç”¨æ¨¡å—
from src.eval.evaluator import Evaluator
from src.viz.visualizer import Visualizer
from src.common.output_manager import OutputManager
from src.common.train_monitor import TrainMonitor

# ç¤ºä¾‹æ¨¡å‹å¯¼å…¥ - æ ¹æ®å®é™…æ¨¡å‹æ›¿æ¢
from src.dataio.datasets.seg_dataset_min import SegDatasetMin
from src.models.baseline.unet_min import UNetMin

from src.models.model_zoo import build_model

def parse_args():
    """å‚æ•°é…ç½® - å¯æ ¹æ®ä¸åŒæ¨¡å‹éœ€æ±‚è°ƒæ•´"""
    p = argparse.ArgumentParser("Offline Universal Trainer")
    
    # åŸºç¡€è®­ç»ƒå‚æ•°
    p.add_argument("--cfg", type=str, default=None, help="Optional YAML config")
    p.add_argument("--data_root", type=str, required=True, help="Dataset root path")
    # p.add_argument("--model_type", type=str, default="universal", help="Model type identifier")
    
    # æ•°æ®å‚æ•°
    p.add_argument("--split", type=str, default="train")
    p.add_argument("--img_size", type=int, default=512)
    p.add_argument("--batch_size", type=int, default=6)
    p.add_argument("--val_ratio", type=float, default=0.2)
    p.add_argument("--num_workers", type=int, default=0)
    
    # è®­ç»ƒå‚æ•°
    p.add_argument("--epochs", type=int, default=5)
    p.add_argument("--lr", type=float, default=3e-4)
    # p.add_argument("--num_classes", type=int, default=2)
    
    # ç›‘æ§å’Œè¾“å‡ºå‚æ•°
    p.add_argument("--monitor_interval", type=int, default=10, help="Progress update interval (batches)")
    p.add_argument("--enable_gpu_monitor", action='store_true', default=True, help="Enable GPU monitoring")
    p.add_argument("--save_viz", action='store_true', help="Save visualizations")
    p.add_argument("--viz_samples", type=int, default=50, help="Number of visualization samples")
    
    # è°ƒè¯•å’Œé«˜çº§é€‰é¡¹
    p.add_argument("--debug", action='store_true', help="Enable debug mode")
    p.add_argument("--save_best_only", action='store_true', default=True, help="Only save best checkpoints")

    # ä»»åŠ¡å®šä¹‰
    p.add_argument("--binary", action="store_true",
                   help="äºŒåˆ†ç±»ï¼ˆèƒ†å›Š+å™¨æ¢°=å‰æ™¯=1ï¼‰ã€‚è‹¥å…³é—­åˆ™æŒ‰å¤šç±»è®­ç»ƒã€‚")
    p.add_argument("--num_classes", type=int, default=2,
                   help="å¤šç±»æ—¶>=2ï¼›--binary ç”Ÿæ•ˆæ—¶å¿½ç•¥æ­¤é¡¹ã€‚")
    
    # æ¨¡å‹æ’æ‹”
    p.add_argument("--model", type=str, default="unet_min",
                   choices=["unet_min", "mobile_unet", "adaptive_unet"])
    
    # å…¼å®¹ OutputManager çš„æ¨¡å‹ç±»å‹æ ‡è®°ï¼ˆç”¨äº run ç›®å½•å‘½åï¼‰
    p.add_argument("--model_type", type=str, default=None,
                   help="è‹¥ä¸æŒ‡å®šï¼Œå°†è‡ªåŠ¨ä½¿ç”¨ --model çš„å€¼ã€‚")
    
    return p.parse_args()

def train_one_epoch(
    model, loader, criterion, optimizer, device, monitor, epoch_index, args
):
    model.train()
    running_loss = 0.0
    total = len(loader)

    for step, (images, masks) in enumerate(loader):
        images = images.to(device, non_blocking=True) # [path, 3, H, W]
        masks  = masks.to(device, non_blocking=True)

        optimizer.zero_grad(set_to_none=True)
        logits = model(images)

        # temp: BCE
        loss = criterion(logits, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * images.size(0)

        # monitor progress
        if (step % args.monitor_interval) == 0:
            avg = running_loss / max(1, (step + 1) * args.batch_size)
            monitor.print_progress(
                    epoch_index + 1, args.epochs,
                    step + 1, total,
                    {"loss": avg},
                    refresh=True
                )

    return running_loss / (len(loader.dataset) if hasattr(loader, 'dataset') else (total * args.batch_size))

# Validation
@torch.inference_mode()
def validate(model, loader, criterion, device):
    evaluator = Evaluator(device=device, threshold=0.5)
    # evaluator.evaluateï¼š
    # - forward + BCE loss
    # - use Sigmoid>0.5 
    # - calculate IoU/Dice/Acc/Precision/Recall
    return evaluator.evaluate(model, loader, criterion)

# 
def main():
    args = parse_args()
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # train monitor
    monitor = TrainMonitor(enable_gpu_monitor=args.enable_gpu_monitor)
    monitor.start_timing()

    # output manager
    model_tag  = args.model if args.model_type is None else args.model_type
    output_mgr = OutputManager(model_type=model_tag)
    output_mgr.save_config(vars(args))

    # Dataloader
    full_dataset = SegDatasetMin(args.data_root, dtype=args.split, img_size=args.img_size)
    # split ratio
    val_ratio  = 0.2
    val_size   = int(len(full_dataset) * val_ratio)
    train_size = len(full_dataset) - val_size
    # create datasets with random split and seed
    seed = 42
    train_ds, val_ds = torch.utils.data.random_split(full_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(seed))

    train_loader = DataLoader(train_ds, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)
    val_loader   = DataLoader(val_ds, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers, pin_memory=True)
    print(f"Dataset: Train={len(train_ds)}, Val={len(val_ds)}")

    # Model
    num_classes = 2 if args.binary else args.num_classes
    # model = build_model(args.model, num_classes=num_classes, in_ch=3).to(device)

    # temp: Loss function
    if args.binary:
        # äºŒåˆ†ç±»ï¼šæ¨¡å‹è¾“å‡º1ä¸ªé€šé“ï¼Œç”¨äºBCEWithLogitsLoss
        model = build_model(args.model, num_classes=1, in_ch=3).to(device)
        criterion = nn.BCEWithLogitsLoss()  # äºŒåˆ†ç±»ç”¨BCE
    else:
        # å¤šåˆ†ç±»ï¼šæ¨¡å‹è¾“å‡ºnum_classesä¸ªé€šé“ï¼Œç”¨äºCrossEntropyLoss  
        model = build_model(args.model, num_classes=args.num_classes, in_ch=3).to(device)
        criterion = nn.CrossEntropyLoss()   # å¤šåˆ†ç±»ç”¨CE

    # Optimizer
    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)
    best_val_loss = float("inf")

    print("=" * 80) # Start training
    print(f"Start Training ({args.model}) for {args.epochs} epoch(s)...")

    # Training loop
    for epoch in range(args.epochs):
        avg_train = train_one_epoch(model, train_loader, criterion, optimizer, device, monitor, epoch, args)
        print(f"Epoch [{epoch + 1}/{args.epochs}], Train Loss: {avg_train:.4f}")

        # val_metrics = evaluator.evaluate(model, val_loader, criterion)
        val_metrics = validate(model, val_loader, criterion, device)

        print(
            f"[Epoch {epoch+1}] "
            f"Val loss: {val_metrics['val_loss']:.4f} | "
            f"IoU: {val_metrics['iou']:.4f} | Dice: {val_metrics['dice']:.4f} | "
            f"Acc: {val_metrics['accuracy']:.4f} | Prec: {val_metrics['precision']:.4f} | Rec: {val_metrics['recall']:.4f}"
        )

        combined_metrics = {"train_loss": avg_train}
        combined_metrics.update(val_metrics)
        output_mgr.save_metrics_csv(combined_metrics, epoch + 1)

        # save checkpoints
        if val_metrics['val_loss'] < best_val_loss:
            best_val_loss = val_metrics['val_loss']
            output_mgr.save_model(model, epoch + 1, val_metrics)
            print(f"Saved best model at epoch {epoch + 1} with loss {val_metrics['val_loss']:.4f}")

        # ğŸ†• æ·»åŠ  epoch æ€»ç»“ (ä» train_offline_min ç§»æ¤)
        train_metrics = {"loss": avg_train}
        monitor.print_epoch_summary(epoch + 1, train_metrics, val_metrics)


   # è®­ç»ƒå®Œæˆåçš„å¯è§†åŒ– (åœ¨è®­ç»ƒå¾ªç¯å¤–)
    if args.save_viz:
        print("\n-- Loading Best Model for Visualization --")
        
        # åŠ è½½æœ€ä½³æ¨¡å‹
        best_model_path = output_mgr.get_best_checkpoint()  # æ³¨æ„æ–¹æ³•å
        if best_model_path and os.path.exists(best_model_path):
            checkpoint = torch.load(best_model_path, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ“ Loaded best model from {best_model_path}")
        
        print("-- Saving Visualizations --")
        visualizer = Visualizer()
        viz_dir = output_mgr.get_vis_dir()
        
        visualizer.save_comparison_predictions(
            model, val_loader, viz_dir, max_samples=args.viz_samples, device=device
        )
        visualizer.save_basic_predictions(
            model, val_loader, viz_dir, max_samples=args.viz_samples, device=device
        )

    # Save final model
    output_mgr.save_model(model)

    # Print summary
    summary = output_mgr.get_run_summary()
    print(f"\n--> Train Completed <--")
    print(f"Results saved to: {summary['run_dir']}")
    print(f"Metrics: {val_metrics['val_loss']:.4f}, {val_metrics['iou']:.4f}, {val_metrics['dice']:.4f}, {val_metrics['accuracy']:.4f}")

if __name__ == "__main__":
    main()

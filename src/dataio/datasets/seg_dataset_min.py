"""
æœ€å°åˆ†å‰²æ•°æ®é›†ç±»
æ”¯æŒæ ‡å‡†çš„ images/ å’Œ masks/ ç›®å½•ç»“æ„
"""

import os, glob, cv2, numpy as np, torch
from torch.utils.data import Dataset
from src.common.constants import DATASET_CONFIG

# 
class SegDatasetMin(Dataset):
    def __init__(self, data_root: str, dtype: str = "train", img_size: int = 512,
            return_multiclass: bool = False,
            class_id_map: dict | None = None,
            ignore_index: int = 255
        ):

        self.data_root = os.path.abspath(data_root)
        self.dtype = dtype if dtype is not None else ""
        self.img_size = int(img_size)

        self.return_multiclass = bool(return_multiclass)
        self.ignore_index = int(ignore_index)

        self.class_id_map = class_id_map or DATASET_CONFIG["SEG8K_CLASS_MAPPING"]

        # get dataset specific for seg8k (for current baseline, and offline in later process)
        # 
        pattern_img = DATASET_CONFIG["SEG8K_IMAGE_PATTERNS"]

        # 
        cand_imgs = []

        #
        for each in pattern_img:
            cand_imgs.extend(
                glob.glob(
                    os.path.join(self.data_root, each),
                    recursive = True
                )
            )
        cand_imgs = [each for each in cand_imgs if "mask" not in os.path.basename(each).lower()]

        #
        pairs = []

        for img_path in sorted(set(cand_imgs)):
            # match mask priority: mask > watershed_mask > color_mask
            stem, _ = os.path.splitext(img_path) # remove extension

            if self.return_multiclass:
                # å¤šåˆ†ç±»ï¼šä¼˜å…ˆç²¾ç¡®mask
                candidates = self._get_multiclass_mask_candidates(stem)
            else:
                # äºŒåˆ†ç±»ï¼šå¯ä»¥ä½¿ç”¨è¿‘ä¼¼mask
                candidates = self._get_binary_mask_candidates(stem)

            mask_path = next((
                c for c in candidates if os.path.exists(c)
            ), None)

            if mask_path is not None:
                pairs.append((img_path, mask_path))

        assert len(pairs) > 0, (
            f"No image-mask pairs found under {self.data_root}.\n"
            "Example expected: .../frame_80_endo.png  +  .../frame_80_endo_color_mask.png")
        
        self.pairs = pairs # [(img_path, mask_path), ...]
        
        # æ•°æ®é›†æ€»ç»“è¾“å‡º
        mask_types = {}
        for _, mask_path in self.pairs[:20]:  # æ£€æŸ¥å‰20ä¸ªæ ·æœ¬çš„ç±»å‹åˆ†å¸ƒ
            if mask_path.endswith('_endo_watershed_mask.png'):
                mask_types['watershed'] = mask_types.get('watershed', 0) + 1
            elif mask_path.endswith('_precise_gt.png'):
                mask_types['precise_gt'] = mask_types.get('precise_gt', 0) + 1
            else:
                mask_types['original'] = mask_types.get('original', 0) + 1
        
        print(f"ğŸ“ æ•°æ®é›†åŠ è½½å®Œæˆ: {len(self.pairs)} å¯¹å›¾åƒ-æ ‡ç­¾")
        if self.return_multiclass:
            print(f"ğŸ¯ å¤šåˆ†ç±»æ¨¡å¼: WatershedåŒºåŸŸâ†’è®­ç»ƒç±»åˆ«æ˜ å°„")
        else:
            print(f"ğŸ¯ äºŒåˆ†ç±»æ¨¡å¼: èƒ†å›Š+å™¨æ¢° vs èƒŒæ™¯")
        
        dominant_type = max(mask_types, key=mask_types.get) if mask_types else 'unknown'
        print(f"ğŸ·ï¸  ä¸»è¦æ ‡ç­¾ç±»å‹: {dominant_type} ({mask_types.get(dominant_type, 0)}/{min(20, len(self.pairs))} æ ·æœ¬)")
        print(f"ğŸ“ å›¾åƒå°ºå¯¸: {self.img_size}x{self.img_size}")
        print("-" * 50)

    def __len__(self):
       return len(self.pairs)

    def __getitem__(self, index):
        img_path, mask_path = self.pairs[index]

        #  read images
        img = cv2.imread(img_path, cv2.IMREAD_COLOR) # from BGR to RGB
        if img is None:
            raise FileNotFoundError(f"Image not found: {img_path}")
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        
        img = cv2.resize(img,
                         (self.img_size, self.img_size),
                         interpolation = cv2.INTER_LINEAR) # resize to target size (same size for both img and mask)
        img = img.astype(np.float32) / 255.0
        img = np.transpose(img, (2, 0, 1))  # HWC to CHW

        # read mask
        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
        if mask is None:
            raise FileNotFoundError(f"Mask not found: {mask_path}")
        
        # å¤„ç†ç²¾ç¡®GTæ–‡ä»¶ï¼ˆå•é€šé“ï¼‰å’ŒåŸå§‹maskæ–‡ä»¶ï¼ˆå¯èƒ½æ˜¯3é€šé“ï¼‰
        if mask.ndim == 3:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç²¾ç¡®GTï¼ˆåº”è¯¥æ˜¯å•é€šé“ä½†è¢«ä¿å­˜ä¸º3é€šé“ï¼‰
            if os.path.basename(mask_path).endswith('_precise_gt.png'):
                # ç²¾ç¡®GTï¼šå–ç¬¬ä¸€ä¸ªé€šé“ï¼ˆæ‰€æœ‰é€šé“åº”è¯¥ç›¸åŒï¼‰
                mask = mask[:, :, 0]
                if index < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                    print(f"[PRECISE_GT] ä½¿ç”¨ç²¾ç¡®GT: {os.path.basename(mask_path)}")
            else:
                # åŸå§‹maskï¼šè½¬ä¸ºç°åº¦å›¾
                mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
                # ç§»é™¤å†—ä½™çš„ORIGINALè¾“å‡ºï¼Œå› ä¸ºå¤§éƒ¨åˆ†éƒ½æ˜¯watershed mask
        else:
            if index < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                print(f"[SINGLE_CH] ä½¿ç”¨å•é€šé“mask: {os.path.basename(mask_path)}")

        if self.return_multiclass:
            # å¤šç±»ï¼šæ ¹æ® class_id_map åš ID æ˜ å°„ï¼ŒæœªçŸ¥å€¼ -> ignore_index
            m = np.full_like(mask, fill_value=self.ignore_index, dtype=np.uint8)

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨watershed mask
            if os.path.basename(mask_path).endswith('_endo_watershed_mask.png'):
                # Watershedå¤„ç†ï¼šé‡æ–°ç¼–å·åŒºåŸŸID
                unique_regions = np.unique(mask)
                region_mapping = {}
                
                # èƒŒæ™¯å§‹ç»ˆä¸º0
                region_mapping[0] = 0
                
                # å…¶ä»–åŒºåŸŸé‡æ–°ç¼–å·ä¸º1, 2, 3...
                class_id = 1
                for region_id in unique_regions:
                    if region_id != 0 and region_id != 255 and class_id < 10:  # è·³è¿‡èƒŒæ™¯å’Œignore_index
                        region_mapping[region_id] = class_id
                        class_id += 1
                
                # åº”ç”¨æ˜ å°„
                for original_id, new_id in region_mapping.items():
                    m[mask == original_id] = new_id
                
                # ä¿æŒignore_indexä¸å˜
                m[mask == 255] = self.ignore_index
                
                # åªæ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯ï¼Œä¹‹ååªæ˜¾ç¤ºç®€åŒ–ç‰ˆæœ¬
                if index < 5:
                    print(f"  [WATERSHED] åŒºåŸŸé‡æ–°ç¼–å·: {len(unique_regions)}ä¸ªåŸå§‹åŒºåŸŸâ†’{class_id-1}ä¸ªè®­ç»ƒç±»åˆ«")
                elif index == 5:
                    print(f"  [WATERSHED] åç»­æ ·æœ¬åŒºåŸŸç¼–å·å°†é™é»˜å¤„ç†...")
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç²¾ç¡®GT  
            elif os.path.basename(mask_path).endswith('_precise_gt.png'):
                # ç²¾ç¡®GTï¼šç›´æ¥ä½¿ç”¨ï¼Œä¸éœ€è¦é‡æ–°æ˜ å°„
                from src.common.constants import DATASET_CONFIG
                if "PRECISE_GT_CLASS_MAPPING" in DATASET_CONFIG:
                    precise_mapping = DATASET_CONFIG["PRECISE_GT_CLASS_MAPPING"]
                    for mask_id, train_name in precise_mapping.items():
                        m[mask == mask_id] = train_name
                    if index < 3:
                        print(f"  [PRECISE_GT] ç›´æ¥ä½¿ç”¨ç²¾ç¡®ç±»åˆ«æ˜ å°„")
                else:
                    # å¦‚æœæ²¡æœ‰ç²¾ç¡®æ˜ å°„ï¼Œä½¿ç”¨åŸå§‹æ˜ å°„
                    for mask_id, train_name in self.class_id_map.items():
                        m[mask == mask_id] = train_name
                    if index < 3:
                        print(f"  [PRECISE_GT] ä½¿ç”¨åŸå§‹ç±»åˆ«æ˜ å°„")
            else:
                # åŸå§‹maskï¼šä½¿ç”¨åŸæœ‰æ˜ å°„é€»è¾‘
                for mask_id, train_name in self.class_id_map.items():
                    m[mask == mask_id] = train_name
                if index < 3:
                    print(f"  [ORIGINAL] ä½¿ç”¨åŸå§‹ç±»åˆ«æ˜ å°„")
            
            # æœ€è¿‘é‚»ç¼©æ”¾ï¼Œä¿æŒç¦»æ•£æ ‡ç­¾ä¸è¢«æ±¡æŸ“
            m           = cv2.resize(m, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)
            mask_tensor = torch.from_numpy(m).long()        # [H, W] for cross entropy loss
            img_tensor  = torch.from_numpy(img).float()     # [3, H, W] for input to model

            # sanity check - åªæ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
            if index < 5:
                unique = np.unique(m[m != self.ignore_index])
                # æ£€æµ‹maskç±»å‹
                if os.path.basename(mask_path).endswith('_endo_watershed_mask.png'):
                    mask_type = "WATERSHED"
                elif os.path.basename(mask_path).endswith('_precise_gt.png'):
                    mask_type = "PRECISE_GT"  
                else:
                    mask_type = "ORIGINAL"
                print(f"[MC] Sample {index} ({mask_type}): classes={unique.tolist()} (ignore {self.ignore_index})")
            elif index == 5:
                print(f"[MC] æ•°æ®åŠ è½½æ­£å¸¸ï¼Œåç»­æ ·æœ¬å°†é™é»˜å¤„ç†...")
            return img_tensor, mask_tensor
        else:
            # binary
            fg = ((mask == 12) | (mask == 13) | (mask == 21) | (mask == 22)).astype(np.uint8)  # èƒ†å›Š+å™¨æ¢°
            fg = cv2.resize(fg, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)

            mask_tensor = torch.from_numpy(fg)[None, ...].float()
            img_tensor  = torch.from_numpy(img)

            if index < 5:
                foreground_ratio = float(fg.mean())
                print(f"[BIN] Sample {index}: Foreground ratio={foreground_ratio:.3f}")
            elif index == 5:
                print(f"[BIN] äºŒåˆ†ç±»æ•°æ®åŠ è½½æ­£å¸¸ï¼Œåç»­æ ·æœ¬å°†é™é»˜å¤„ç†...")
            return img_tensor, mask_tensor

    def _get_multiclass_mask_candidates(self, stem):
        """å¤šåˆ†ç±»ä»»åŠ¡çš„maskå€™é€‰åˆ—è¡¨ï¼ˆwatershedä¼˜å…ˆï¼‰"""
        return [
            stem.replace("_endo", "_endo_watershed_mask") + ".png", # æœ€ä¼˜ï¼šwatershedåŒºåŸŸåˆ†å‰²
            stem.replace("_endo", "_precise_gt") + ".png",          # æ¬¡é€‰ï¼šç²¾ç¡®GTï¼ˆå¦‚æœæœ‰ï¼‰
            stem.replace("_endo", "_endo_mask") + ".png",           # å¤‡é€‰ï¼šåŸå§‹mask
        ]

    def _get_binary_mask_candidates(self, stem):
        """äºŒåˆ†ç±»ä»»åŠ¡çš„maskå€™é€‰åˆ—è¡¨ï¼ˆå¯ç”¨è¿‘ä¼¼ï¼‰"""
        return [
            stem.replace("_endo", "_endo_mask") + ".png",           # ç²¾ç¡®
            stem.replace("_endo", "_endo_watershed_mask") + ".png", # è¿‘ä¼¼
            stem.replace("_endo_color", "_endo_color_mask") + ".png", # ç²—ç³™ä½†å¯ç”¨
            stem.replace("_endo", "_endo_color_mask") + ".png",
        ]

    def analyze_mask_distribution(self, num_samples=50):
            """åˆ†æmaskåˆ†å¸ƒæƒ…å†µ"""
            print("ğŸ” åˆ†æå‰æ™¯åˆ†å¸ƒï¼ˆçœ‹äºŒåˆ†ç±»åˆå¹¶åçš„å‰æ™¯å æ¯”ï¼‰...")
            # print("Analyzing foreground distribution...")
            
            foreground_ratios = []
            for i in range(min(num_samples, len(self.pairs))):
                _, mask_path = self.pairs[i]
                
                # è¯»å–åŸå§‹mask
                raw_mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)
                if raw_mask.ndim == 3:
                    raw_mask = cv2.cvtColor(raw_mask, cv2.COLOR_BGR2GRAY)
                
                # åº”ç”¨èƒ†å›Š+å™¨æ¢°ç­–ç•¥
                processed_mask = ((raw_mask == 12) | (raw_mask == 13) | (raw_mask == 21) | (raw_mask == 22)).astype(np.uint8)
                
                foreground_ratio = processed_mask.mean()
                foreground_ratios.append(foreground_ratio)
                
                if i < 5:  # æ‰“å°å‰5ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯
                    unique_raw = np.unique(raw_mask)
                    print(f"  Sample {i}: Raw values {unique_raw} -> Foreground ratio {foreground_ratio:.3f}")
            
            avg_ratio = np.mean(foreground_ratios)
            print(f"å¹³å‡å‰æ™¯æ¯”ä¾‹: {avg_ratio:.3f}")
            print(f"å‰æ™¯æ¯”ä¾‹èŒƒå›´: {np.min(foreground_ratios):.3f} - {np.max(foreground_ratios):.3f}")
            
            return foreground_ratios